{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendador de películas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el sistema de recomendación se va a implentar el enfoque de filtrado colaborativo que consiste en contruir un modelo a partir de las calificaciones dadas por cada usuario y los usuraios similares a éste. Con este modelo se podrán predecir las calificaciones de las películas no vistas por el usuario para así, sugerirle las que obtengan mayor puntuación en dicha predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de librerías e inicio de la sesión de Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, StructType, StructField, StringType, DoubleType\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "       .appName(\"Recomendador peliculas\")\\\n",
    "       .config(\"spark.some.config.option\", \"config-value\")\\\n",
    "       .getOrCreate()\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a utilizar el archivo `ratings.dat` que consta de tres campos por registro; el id del usuario, el id de la película y la calificación del usuario a dicha película respectivamente.\n",
    "\n",
    "Para facilitar la carga del archivo, previamente, se ha reemplazado el separador `::` por `:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|user_id|movie_id|rating|\n",
      "+-------+--------+------+\n",
      "|      1|    1193|   5.0|\n",
      "|      1|     661|   3.0|\n",
      "|      1|     914|   3.0|\n",
      "|      1|    3408|   4.0|\n",
      "|      1|    2355|   5.0|\n",
      "|      1|    1197|   3.0|\n",
      "|      1|    1287|   5.0|\n",
      "|      1|    2804|   5.0|\n",
      "|      1|     594|   4.0|\n",
      "|      1|     919|   4.0|\n",
      "|      1|     595|   5.0|\n",
      "|      1|     938|   4.0|\n",
      "|      1|    2398|   4.0|\n",
      "|      1|    2918|   4.0|\n",
      "|      1|    1035|   5.0|\n",
      "|      1|    2791|   4.0|\n",
      "|      1|    2687|   3.0|\n",
      "|      1|    2018|   4.0|\n",
      "|      1|    3105|   5.0|\n",
      "|      1|    2797|   4.0|\n",
      "+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse dating agency ratings data as a Spark dataframe\n",
    "ratings = \"ratings.dat\"\n",
    "schema = StructType([StructField(\"user_id\", IntegerType(), False),\n",
    "                     StructField(\"movie_id\", IntegerType(), False),\n",
    "                     StructField(\"rating\", DoubleType(), True)])\n",
    "ratings_df = spark.read.format(\"csv\").option(\"header\", \"false\").option(\"delimiter\", \":\").schema(schema).load(ratings)\n",
    "ratings_df = ratings_df.na.drop(how=\"any\")\n",
    "ratings_df.show()\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma adecuada para introducir estos datos en un modelo es con una matriz de iteración donde las filas representan las películas y cada columna corresponde a un usuario o viceversa. Se trata de una matriz dispersa ya que encontramos muchos datos faltantes. Esta dispersión se puede calcular de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos una dispersión del   95.53% \n"
     ]
    }
   ],
   "source": [
    "# Contamos las valoraciones: \n",
    "numerator = ratings_df.select(\"rating\").count()\n",
    "\n",
    "# Contamos el total de usuarios y peliculas únicos:\n",
    "num_users = ratings_df.select(\"user_id\").distinct().count()\n",
    "num_movies = ratings_df.select(\"movie_id\").distinct().count()\n",
    "\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Dispersión: \n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"Tenemos una dispersión del  \", \"%.2f\" % sparsity + \"% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este tipo de datos se aplican algoritmos de factorización matricial. Se va a utilizar el algoritmo ALS (Alternating Least Square) proporcinado por la libreria ML de pyspark que se ejecuta de forma paralela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el algoritmo ALS:\n",
    "\n",
    "als = ALS(userCol=\"user_id\",itemCol=\"movie_id\",ratingCol=\"rating\",coldStartStrategy='drop',nonnegative = True,implicitPrefs = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a ajustar los hiperparamentros entrenando 12 modelos. Mediante la validación cruzada se obtendrá el modelo que mejor se ajusta a los datos utilizando el RMSE como medida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separación en train y test:\n",
    "train, test = ratings_df.randomSplit([0.8, 0.2], seed = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros a probar:\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50]) \\\n",
    "            .addGrid(als.maxIter, [5,10]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1])\\\n",
    "            .build()\n",
    "         \n",
    "# Evaluador:\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName='rmse',\n",
    "    labelCol='rating',\n",
    "    predictionCol='prediction'\n",
    ")\n",
    "\n",
    "\n",
    "#Definimos la validación cruzada:\n",
    "cv = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos entrenamos los modelos y validamos:\n",
    "model = cv.fit(train)\n",
    "\n",
    "# Mejor modelo:\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen y muestran las predicciones del modelo que mejor se ajusta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating|prediction|\n",
      "+-------+--------+------+----------+\n",
      "|   3184|     148|   4.0| 2.9953053|\n",
      "|   3539|     148|   3.0|  3.045854|\n",
      "|   3053|     148|   3.0| 2.5148985|\n",
      "|    660|     463|   3.0| 2.5178556|\n",
      "|   3753|     463|   2.0| 2.5155425|\n",
      "|   5047|     463|   3.0| 2.3473194|\n",
      "|   3709|     463|   3.0| 2.2141466|\n",
      "|    202|     463|   3.0|  2.616348|\n",
      "|   2777|     463|   3.0| 2.9701884|\n",
      "|    721|     463|   4.0| 3.2723997|\n",
      "|   4252|     463|   3.0| 2.3923914|\n",
      "|    934|     463|   3.0| 2.1712956|\n",
      "|    516|     471|   2.0|   2.37645|\n",
      "|   1303|     471|   4.0| 3.3341773|\n",
      "|   3704|     471|   5.0| 4.4221826|\n",
      "|   1884|     471|   2.0| 3.4690475|\n",
      "|   3986|     471|   4.0| 4.1356173|\n",
      "|   4186|     471|   3.0| 3.0597675|\n",
      "|   5222|     471|   4.0| 3.0094497|\n",
      "|   1199|     471|   3.0|  2.342823|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = best_model.transform(test)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571958718805348\n"
     ]
    }
   ],
   "source": [
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
